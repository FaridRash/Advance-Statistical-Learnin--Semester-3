{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dab651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:12.586590Z",
     "iopub.status.busy": "2025-01-22T17:36:12.586260Z",
     "iopub.status.idle": "2025-01-22T17:36:16.602046Z",
     "shell.execute_reply": "2025-01-22T17:36:16.601023Z"
    },
    "id": "g_n67soMKYth",
    "outputId": "be56ee3c-7794-49a8-b564-ef3487c6cf82",
    "papermill": {
     "duration": 4.024715,
     "end_time": "2025-01-22T17:36:16.604837",
     "exception": false,
     "start_time": "2025-01-22T17:36:12.580122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Advance-Statistical-Learnin--Semester-3'...\r\n",
      "remote: Enumerating objects: 49, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (49/49), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\r\n",
      "remote: Total 49 (delta 10), reused 11 (delta 0), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (49/49), 33.02 MiB | 19.92 MiB/s, done.\r\n",
      "Resolving deltas: 100% (10/10), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/FaridRash/Advance-Statistical-Learnin--Semester-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d9e575",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:16.615270Z",
     "iopub.status.busy": "2025-01-22T17:36:16.614985Z",
     "iopub.status.idle": "2025-01-22T17:36:19.511424Z",
     "shell.execute_reply": "2025-01-22T17:36:19.510278Z"
    },
    "id": "1aab1c42",
    "papermill": {
     "duration": 2.903653,
     "end_time": "2025-01-22T17:36:19.513491",
     "exception": false,
     "start_time": "2025-01-22T17:36:16.609838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e43cc5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:19.524271Z",
     "iopub.status.busy": "2025-01-22T17:36:19.523736Z",
     "iopub.status.idle": "2025-01-22T17:36:19.948439Z",
     "shell.execute_reply": "2025-01-22T17:36:19.947247Z"
    },
    "id": "8d85ec77",
    "papermill": {
     "duration": 0.431529,
     "end_time": "2025-01-22T17:36:19.950139",
     "exception": false,
     "start_time": "2025-01-22T17:36:19.518610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/working/Advance-Statistical-Learnin--Semester-3/Dataset/EURUSD-2000-2020-15m.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44480fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:19.960080Z",
     "iopub.status.busy": "2025-01-22T17:36:19.959682Z",
     "iopub.status.idle": "2025-01-22T17:36:19.991668Z",
     "shell.execute_reply": "2025-01-22T17:36:19.990576Z"
    },
    "id": "JMBWOgcKKvoc",
    "papermill": {
     "duration": 0.038658,
     "end_time": "2025-01-22T17:36:19.993382",
     "exception": false,
     "start_time": "2025-01-22T17:36:19.954724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def EMA(df, base, target, period, alpha=False):\n",
    "    \"\"\"\n",
    "    Function to compute Exponential Moving Average (EMA)\n",
    "    \"\"\"\n",
    "    con = pd.concat([df[:period][base].rolling(window=period).mean(), df[period:][base]])\n",
    "    if (alpha == False):\n",
    "        df[target] = con.ewm(span=period, adjust=False).mean()\n",
    "    else:\n",
    "        df[target] = con.ewm(alpha=alpha, adjust=False).mean()\n",
    "    return df\n",
    "\n",
    "df_ema = EMA(df, 'CLOSE', 'EMA_20', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a893db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:20.003347Z",
     "iopub.status.busy": "2025-01-22T17:36:20.003027Z",
     "iopub.status.idle": "2025-01-22T17:36:20.026264Z",
     "shell.execute_reply": "2025-01-22T17:36:20.025045Z"
    },
    "id": "3Vl1-9aRMdKj",
    "outputId": "6ebdbb97-8e6b-4fb3-80ca-cc0dce31d92d",
    "papermill": {
     "duration": 0.029929,
     "end_time": "2025-01-22T17:36:20.027998",
     "exception": false,
     "start_time": "2025-01-22T17:36:19.998069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>EMA_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.01.03 00:00:00</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.01.03 00:15:00</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>1.0076</td>\n",
       "      <td>1.0078</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.01.03 00:30:00</td>\n",
       "      <td>1.0089</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000.01.03 00:45:00</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>1.0078</td>\n",
       "      <td>1.0078</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.01.03 01:00:00</td>\n",
       "      <td>1.0133</td>\n",
       "      <td>1.0120</td>\n",
       "      <td>1.0129</td>\n",
       "      <td>1.0122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE_TIME    HIGH     LOW    OPEN   CLOSE  EMA_20\n",
       "0  2000.01.03 00:00:00  1.0080  1.0073  1.0073  1.0077     NaN\n",
       "1  2000.01.03 00:15:00  1.0087  1.0076  1.0078  1.0086     NaN\n",
       "2  2000.01.03 00:30:00  1.0089  1.0079  1.0087  1.0079     NaN\n",
       "3  2000.01.03 00:45:00  1.0132  1.0078  1.0078  1.0128     NaN\n",
       "4  2000.01.03 01:00:00  1.0133  1.0120  1.0129  1.0122     NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ema.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172fedd",
   "metadata": {
    "papermill": {
     "duration": 0.004069,
     "end_time": "2025-01-22T17:36:20.037251",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.033182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b8bdf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:20.046936Z",
     "iopub.status.busy": "2025-01-22T17:36:20.046591Z",
     "iopub.status.idle": "2025-01-22T17:36:20.050553Z",
     "shell.execute_reply": "2025-01-22T17:36:20.049824Z"
    },
    "id": "xiqFtiQxMebF",
    "papermill": {
     "duration": 0.010021,
     "end_time": "2025-01-22T17:36:20.051582",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.041561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_packs(df, pack_size):\n",
    "\n",
    "    numerical_data = df[['HIGH', 'LOW', 'OPEN', 'CLOSE', 'EMA_20']].values\n",
    "    \n",
    "    num_packs = len(numerical_data) - pack_size + 1\n",
    "    \n",
    "    packs = np.array([numerical_data[i:i + pack_size] for i in range(num_packs)])\n",
    "    \n",
    "    return packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a06feae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:20.061657Z",
     "iopub.status.busy": "2025-01-22T17:36:20.061382Z",
     "iopub.status.idle": "2025-01-22T17:36:20.914809Z",
     "shell.execute_reply": "2025-01-22T17:36:20.913680Z"
    },
    "papermill": {
     "duration": 0.860175,
     "end_time": "2025-01-22T17:36:20.916384",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.056209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pack_size = 100 \n",
    "packs = create_packs(df_ema, pack_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff7a2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:20.927050Z",
     "iopub.status.busy": "2025-01-22T17:36:20.926725Z",
     "iopub.status.idle": "2025-01-22T17:36:20.931860Z",
     "shell.execute_reply": "2025-01-22T17:36:20.931113Z"
    },
    "papermill": {
     "duration": 0.011806,
     "end_time": "2025-01-22T17:36:20.933258",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.921452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (500652, 100, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(packs), packs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69787a8a",
   "metadata": {
    "papermill": {
     "duration": 0.004171,
     "end_time": "2025-01-22T17:36:20.942397",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.938226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b3ea20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:20.952204Z",
     "iopub.status.busy": "2025-01-22T17:36:20.951884Z",
     "iopub.status.idle": "2025-01-22T17:36:20.956001Z",
     "shell.execute_reply": "2025-01-22T17:36:20.955058Z"
    },
    "papermill": {
     "duration": 0.010646,
     "end_time": "2025-01-22T17:36:20.957437",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.946791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_packs(packs):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    num_packs, pack_size, num_features = packs.shape\n",
    "    reshaped_packs = packs.reshape(-1, num_features)\n",
    "    \n",
    "    normalized_data = scaler.fit_transform(reshaped_packs)\n",
    "    \n",
    "    normalized_packs = normalized_data.reshape(num_packs, pack_size, num_features)\n",
    "    \n",
    "    return normalized_packs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5404513f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:20.967435Z",
     "iopub.status.busy": "2025-01-22T17:36:20.967166Z",
     "iopub.status.idle": "2025-01-22T17:36:33.167482Z",
     "shell.execute_reply": "2025-01-22T17:36:33.166829Z"
    },
    "papermill": {
     "duration": 12.206969,
     "end_time": "2025-01-22T17:36:33.169109",
     "exception": false,
     "start_time": "2025-01-22T17:36:20.962140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized packs: (500652, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "normalized_packs = normalize_packs(packs)\n",
    "\n",
    "print(\"Shape of normalized packs:\", normalized_packs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacf2c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:33.180030Z",
     "iopub.status.busy": "2025-01-22T17:36:33.179705Z",
     "iopub.status.idle": "2025-01-22T17:36:34.061271Z",
     "shell.execute_reply": "2025-01-22T17:36:34.060206Z"
    },
    "papermill": {
     "duration": 0.888632,
     "end_time": "2025-01-22T17:36:34.062889",
     "exception": false,
     "start_time": "2025-01-22T17:36:33.174257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "val_size = 0.1\n",
    "test_size = 0.2\n",
    "\n",
    "packs_train, packs_temp, norm_packs_train, norm_packs_temp = train_test_split(\n",
    "    packs, normalized_packs, test_size=(val_size + test_size), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad024a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.072991Z",
     "iopub.status.busy": "2025-01-22T17:36:34.072664Z",
     "iopub.status.idle": "2025-01-22T17:36:34.341154Z",
     "shell.execute_reply": "2025-01-22T17:36:34.340077Z"
    },
    "papermill": {
     "duration": 0.275138,
     "end_time": "2025-01-22T17:36:34.342784",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.067646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_ratio = val_size / (val_size + test_size)  # Adjust ratio for temp split\n",
    "packs_val, packs_test, norm_packs_val, norm_packs_test = train_test_split(\n",
    "    packs_temp, norm_packs_temp, test_size=(1 - val_ratio), random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e753a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.352699Z",
     "iopub.status.busy": "2025-01-22T17:36:34.352387Z",
     "iopub.status.idle": "2025-01-22T17:36:34.360521Z",
     "shell.execute_reply": "2025-01-22T17:36:34.359085Z"
    },
    "papermill": {
     "duration": 0.014936,
     "end_time": "2025-01-22T17:36:34.362297",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.347361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packs Train size: 350456\n",
      "Packs Validation size: 50065\n",
      "Packs Test size: 100131\n",
      "-----------\n",
      "Normalized Train size: 350456\n",
      "Normalized Validation size: 50065\n",
      "Normalized Test size: 100131\n"
     ]
    }
   ],
   "source": [
    "print(\"Packs Train size:\", len(packs_train))\n",
    "print(\"Packs Validation size:\", len(packs_val))\n",
    "print(\"Packs Test size:\", len(packs_test))\n",
    "print('-----------')\n",
    "print(\"Normalized Train size:\", len(norm_packs_train))\n",
    "print(\"Normalized Validation size:\", len(norm_packs_val))\n",
    "print(\"Normalized Test size:\", len(norm_packs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a082e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.372940Z",
     "iopub.status.busy": "2025-01-22T17:36:34.372633Z",
     "iopub.status.idle": "2025-01-22T17:36:34.376698Z",
     "shell.execute_reply": "2025-01-22T17:36:34.375325Z"
    },
    "papermill": {
     "duration": 0.011283,
     "end_time": "2025-01-22T17:36:34.378575",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.367292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_state(packs, index):\n",
    "\n",
    "    state = packs[index]\n",
    "    next_state = packs[index + 1] if index + 1 < len(packs) else None\n",
    "    return state, next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b191f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.388926Z",
     "iopub.status.busy": "2025-01-22T17:36:34.388555Z",
     "iopub.status.idle": "2025-01-22T17:36:34.392764Z",
     "shell.execute_reply": "2025-01-22T17:36:34.391851Z"
    },
    "papermill": {
     "duration": 0.010864,
     "end_time": "2025-01-22T17:36:34.394316",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.383452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_action(q_values, epsilon):\n",
    "\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = np.random.choice([0, 1, 2])\n",
    "    else:\n",
    "        action = np.argmax(q_values)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d488fd49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.404796Z",
     "iopub.status.busy": "2025-01-22T17:36:34.404425Z",
     "iopub.status.idle": "2025-01-22T17:36:34.409663Z",
     "shell.execute_reply": "2025-01-22T17:36:34.408980Z"
    },
    "papermill": {
     "duration": 0.011553,
     "end_time": "2025-01-22T17:36:34.410740",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.399187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_reward(action, open_price, stop_loss, target, target_multiplier, close_price, low, high, max_hold, current_hold):\n",
    "\n",
    "    if action == 'buy':\n",
    "        if low <= stop_loss: \n",
    "            return -1.0 \n",
    "        elif high >= target:\n",
    "            return target_multiplier\n",
    "\n",
    "    elif action == 'sell':\n",
    "        if high >= stop_loss: \n",
    "            return -1.0\n",
    "        elif low <= target: \n",
    "            return target_multiplier\n",
    "\n",
    "    elif current_hold >= max_hold:\n",
    "        return (close_price - open_price) / open_price - 0.1 \n",
    "\n",
    "    elif action == 'hold':\n",
    "        return -0.05\n",
    "\n",
    "    # Default: No action has triggered any event yet\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "765885db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.421173Z",
     "iopub.status.busy": "2025-01-22T17:36:34.420784Z",
     "iopub.status.idle": "2025-01-22T17:36:34.428574Z",
     "shell.execute_reply": "2025-01-22T17:36:34.427276Z"
    },
    "papermill": {
     "duration": 0.014875,
     "end_time": "2025-01-22T17:36:34.430344",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.415469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transition_to_next_state(current_state, action, current_hold, packs, pack_index, \n",
    "                             open_price=None, stop_loss=None, target=None, \n",
    "                             max_hold=None, balance=1000, epsilon=0.1, target_multiplier=2):\n",
    "    if pack_index >= len(packs) - 1:\n",
    "        return None, 0.0, None, None, None, 0, balance, True  # End of episode\n",
    "\n",
    "    # Move to the next pack\n",
    "    next_pack = packs[pack_index + 1]\n",
    "    next_state = next_pack\n",
    "    low, high, close = next_pack[1], next_pack[2], next_pack[3]  # [H, L, O, C]\n",
    "\n",
    "    # Reward initialization\n",
    "    reward = 0.0\n",
    "    done = False\n",
    "\n",
    "    # Action: Buy\n",
    "    if action == \"buy\" and open_price is None:\n",
    "        open_price = close  # Open a new buy position\n",
    "        stop_loss_multiplier = random.uniform(0.005, 0.03) if random.random() < epsilon else 0.0175\n",
    "        stop_loss = open_price * (1 - stop_loss_multiplier)\n",
    "        target = open_price * (1 + target_multiplier * stop_loss_multiplier)  # Target is 2x stop-loss\n",
    "        current_hold = 0  # Reset holding period\n",
    "\n",
    "    # Action: Sell\n",
    "    elif action == \"sell\" and open_price is None:\n",
    "        open_price = close  # Open a new sell position\n",
    "        stop_loss_multiplier = random.uniform(0.005, 0.03) if random.random() < epsilon else 0.0175\n",
    "        stop_loss = open_price * (1 + stop_loss_multiplier)\n",
    "        target = open_price * (1 - target_multiplier * stop_loss_multiplier)  # Target is 2x stop-loss\n",
    "        current_hold = 0  # Reset holding period\n",
    "\n",
    "    # Action: Hold\n",
    "    elif action == \"hold\" and open_price is not None:\n",
    "        current_hold += 1  # Increment holding period\n",
    "\n",
    "    # Reward Calculation (centralized using `calculate_reward`)\n",
    "    reward = calculate_reward(\n",
    "        action=action,\n",
    "        open_price=open_price,\n",
    "        stop_loss=stop_loss,\n",
    "        target=target,\n",
    "        target_multiplier=target_multiplier,\n",
    "        close_price=close,\n",
    "        low=low,\n",
    "        high=high,\n",
    "        max_hold=max_hold,\n",
    "        current_hold=current_hold,\n",
    "    )\n",
    "\n",
    "    # Update balance based on reward\n",
    "    balance += reward * balance\n",
    "\n",
    "    # Reset parameters if position is closed\n",
    "    if reward != 0.0:  # A reward signifies that a stop-loss, target, or hold limit was hit\n",
    "        open_price, stop_loss, target = None, None, None\n",
    "        current_hold = 0\n",
    "\n",
    "    # Determine if the episode is done\n",
    "    if pack_index >= len(packs) - 2:  # Check if the next state would exceed the pack size\n",
    "        done = True\n",
    "\n",
    "    return next_state, reward, open_price, stop_loss, target, current_hold, balance, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f30af15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.441524Z",
     "iopub.status.busy": "2025-01-22T17:36:34.441232Z",
     "iopub.status.idle": "2025-01-22T17:36:34.446576Z",
     "shell.execute_reply": "2025-01-22T17:36:34.445450Z"
    },
    "papermill": {
     "duration": 0.013006,
     "end_time": "2025-01-22T17:36:34.448671",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.435665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_parameters(epsilon, stop_loss_range, target_range, hold_range):\n",
    "    \"\"\"\n",
    "    Function to determine stop-loss, target, and max hold period using epsilon-greedy strategy.\n",
    "\n",
    "    Parameters:\n",
    "    - epsilon: Exploration probability.\n",
    "    - stop_loss_range: Tuple (min_stop_loss, max_stop_loss) for stop-loss percentage range.\n",
    "    - target_range: Tuple (min_target, max_target) for target multiplier range.\n",
    "    - hold_range: Tuple (min_hold, max_hold) for max hold period range.\n",
    "\n",
    "    Returns:\n",
    "    - selected_stop_loss: Stop-loss percentage.\n",
    "    - selected_target: Target multiplier.\n",
    "    - selected_max_hold: Maximum hold period.\n",
    "    \"\"\"\n",
    "    # Stop-loss selection\n",
    "    if np.random.rand() < epsilon:  # Exploration\n",
    "        selected_stop_loss = np.random.uniform(*stop_loss_range)\n",
    "    else:  # Exploitation (use mid-point as an example of learned behavior)\n",
    "        selected_stop_loss = (stop_loss_range[0] + stop_loss_range[1]) / 2\n",
    "\n",
    "    # Target selection\n",
    "    if np.random.rand() < epsilon:  # Exploration\n",
    "        selected_target = np.random.uniform(*target_range)\n",
    "    else:  # Exploitation\n",
    "        selected_target = (target_range[0] + target_range[1]) / 2\n",
    "\n",
    "    # Max hold selection\n",
    "    if np.random.rand() < epsilon:  # Exploration\n",
    "        selected_max_hold = np.random.randint(*hold_range)\n",
    "    else:  # Exploitation\n",
    "        selected_max_hold = (hold_range[0] + hold_range[1]) // 2\n",
    "\n",
    "    return selected_stop_loss, selected_target, selected_max_hold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c76236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.459655Z",
     "iopub.status.busy": "2025-01-22T17:36:34.459329Z",
     "iopub.status.idle": "2025-01-22T17:36:34.466704Z",
     "shell.execute_reply": "2025-01-22T17:36:34.465400Z"
    },
    "papermill": {
     "duration": 0.014758,
     "end_time": "2025-01-22T17:36:34.468527",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.453769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ForexTradingEnv:\n",
    "    def __init__(self, packs, max_hold):\n",
    "        self.packs = packs\n",
    "        self.max_hold = max_hold\n",
    "        self.current_index = 0\n",
    "        self.current_hold = 0\n",
    "        self.open_price = None\n",
    "        self.stop_loss = None\n",
    "        self.target = None\n",
    "        self.balance = 1000  # Starting balance\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment to the initial state.\"\"\"\n",
    "        self.current_index = 0\n",
    "        self.current_hold = 0\n",
    "        self.open_price = None\n",
    "        self.stop_loss = None\n",
    "        self.target = None\n",
    "        self.balance = 1000  # Reset balance\n",
    "        self.done = False\n",
    "        # Correct call to `get_state` with both arguments\n",
    "        state, _ = get_state(self.packs, self.current_index)\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action and transition to the next state.\"\"\"\n",
    "        if self.done:\n",
    "            raise ValueError(\"Cannot step in a finished environment. Call reset().\")\n",
    "\n",
    "        # Current state\n",
    "        current_state, _ = get_state(self.packs, self.current_index)\n",
    "\n",
    "        # Transition to the next state\n",
    "        result = transition_to_next_state(\n",
    "            current_state=current_state,\n",
    "            action=action,\n",
    "            current_hold=self.current_hold,\n",
    "            packs=self.packs,\n",
    "            pack_index=self.current_index,\n",
    "            open_price=self.open_price,\n",
    "            stop_loss=self.stop_loss,\n",
    "            target=self.target,\n",
    "            max_hold=self.max_hold,\n",
    "            balance=self.balance,\n",
    "        )\n",
    "\n",
    "        next_state, reward, self.open_price, self.stop_loss, self.target, self.current_hold, self.balance, self.done = result\n",
    "\n",
    "        # Increment index if not done\n",
    "        if not self.done:\n",
    "            self.current_index += 1\n",
    "\n",
    "        return next_state, reward, self.done\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Render the current environment state.\"\"\"\n",
    "        print(f\"Index: {self.current_index}\")\n",
    "        print(f\"Balance: {self.balance}\")\n",
    "        print(f\"Open Price: {self.open_price}\")\n",
    "        print(f\"Stop Loss: {self.stop_loss}\")\n",
    "        print(f\"Target: {self.target}\")\n",
    "        print(f\"Current Hold: {self.current_hold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a42c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.479493Z",
     "iopub.status.busy": "2025-01-22T17:36:34.479171Z",
     "iopub.status.idle": "2025-01-22T17:36:34.484520Z",
     "shell.execute_reply": "2025-01-22T17:36:34.483074Z"
    },
    "papermill": {
     "duration": 0.012499,
     "end_time": "2025-01-22T17:36:34.486050",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.473551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48538d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T17:36:34.497269Z",
     "iopub.status.busy": "2025-01-22T17:36:34.496983Z",
     "iopub.status.idle": "2025-01-22T17:36:39.131518Z",
     "shell.execute_reply": "2025-01-22T17:36:39.130187Z"
    },
    "papermill": {
     "duration": 4.642212,
     "end_time": "2025-01-22T17:36:39.133675",
     "exception": false,
     "start_time": "2025-01-22T17:36:34.491463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "def train_dqn(env, dqn_model, target_model, replay_buffer, optimizer, batch_size, gamma, epsilon, epsilon_decay, min_epsilon, num_episodes, target_update_freq):\n",
    "    losses = []\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Convert state to tensor\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "\n",
    "            # Select action\n",
    "            q_values = dqn_model(state_tensor)\n",
    "            action = select_action(q_values, epsilon)\n",
    "\n",
    "            # Take action in the environment\n",
    "            next_state, reward, done = env.transition_to_next_step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            # Store transition in replay buffer\n",
    "            replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "            # Update state\n",
    "            state = next_state\n",
    "\n",
    "            # Training step\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                # Sample a batch\n",
    "                transitions = replay_buffer.sample(batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*transitions)\n",
    "\n",
    "                # Convert to tensors\n",
    "                states = torch.FloatTensor(states)\n",
    "                actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "                rewards = torch.FloatTensor(rewards)\n",
    "                next_states = torch.FloatTensor(next_states)\n",
    "                dones = torch.FloatTensor(dones)\n",
    "\n",
    "                # Compute Q values and targets\n",
    "                current_q = dqn_model(states).gather(1, actions).squeeze(1)\n",
    "                max_next_q = target_model(next_states).max(1)[0]\n",
    "                target_q = rewards + gamma * max_next_q * (1 - dones)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = nn.MSELoss()(current_q, target_q.detach())\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update target network\n",
    "        if episode % target_update_freq == 0:\n",
    "            target_model.load_state_dict(dqn_model.state_dict())\n",
    "\n",
    "        # Decay epsilon\n",
    "        epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "        print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}\")\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffd3f1",
   "metadata": {
    "papermill": {
     "duration": 0.005447,
     "end_time": "2025-01-22T17:36:39.145229",
     "exception": false,
     "start_time": "2025-01-22T17:36:39.139782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31.472317,
   "end_time": "2025-01-22T17:36:41.753833",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-22T17:36:10.281516",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
